name: BizInfo Crawling Automation

on:
  schedule:
    - cron: "0 0 * * *"  # 매일 오전 9시 (한국 시간)
  workflow_dispatch:  # 수동 실행

jobs:
  bizinfo-crawling:
    runs-on: ubuntu-latest

    steps:
    - name: Check out the repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.9"

    - name: Install dependencies
      run: pip install -r requirements.txt

    - name: Install Chrome and ChromeDriver
      run: |
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        sudo apt-get install -y chromium-chromedriver

    - name: Set ChromeDriver PATH
      run: |
        echo 'export PATH=$PATH:/usr/lib/chromium-browser/' >> $GITHUB_ENV

    - name: Execute crawling script
      env:
        GMAIL_EMAIL: ${{ secrets.GMAIL_EMAIL }}
        GMAIL_PASSWORD: ${{ secrets.GMAIL_PASSWORD }}
        RECIPIENT_EMAIL: ${{ secrets.RECIPIENT_EMAIL }}
      run: python 1_searching.py
